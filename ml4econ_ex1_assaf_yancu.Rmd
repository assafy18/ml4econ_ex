---
title: "ML4econ - Exercise 1"
author: "Assaf Yancu"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document:
    theme: united
    toc: true
    tod_depth: 3
    toc_float: true
    df_print: paged
  pdf_document:
    toc: true
  word_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval = TRUE,
                      echo = TRUE,
                      warning = FALSE,
                      message = FALSE)
```

# About the Course
1. Applying machine learning (ML) methods to economic issues presents challenges. ML excels at **predicting observable outcomes** using patterns in data. However, ML models are often considered "black boxes," lacking transparency in explaining how predictions are made and the mechanisms driving them. In contrast, economic analysis focuses on understanding causal effects, such as how changes in one variable impact another. Thus, as opposed to ML's robustness in stable environments, economists utilize **counterfactual analysis** to estimate the effects of policies or interventions. Economic methods are structured to uncover underlying mechanisms driving outcomes, relying on theoretical arguments and assumptions to argue with a high probability that the estimates (the prediction for the casual effects) are unbiased, consistent, and efficient.


2. To interpret linear regression coefficients causally, it is essential to rely on underlying assumptions aligned with counterfactual analysis principles, similar to those applied in randomized controlled trials (RCTs). Central to causal inference is the critical assumption of independence between the treatment variable and unobserved factors. This assumption is crucial as it cannot be empirically tested using available data and necessitates theoretical justification. ML relies on the assumption of a stable data generating process (DGP) across both the training and test sets. This means ML methods are not adjusted for instances when the DGP changes; for example, if a factor changes and the entire system shifts accordingly. In other words, counterfactual analysis challenges this underlying assumption of a stable DGP. Note that assuming independence of observations is required in both disciplines, but it can be refined as needed.


3. 
  + a. A linear regression model assumes that the outcome is linearly related to each parameter in the model when holding all others fixed. This assumption is intuitive to a counterfactual analyst who primarily interested in estimating the effect of a one unit change in the variable of interest on the outcome variable. The constant effect induced by the linearity make the results easier for casual inference and policy making.  Note that this linearity in note very restricted since the outcome is only linear in the parameter and not in the variables. For example, the linear estimated parameter of an interaction between two variables resembles the linear dependency of the main effect on another variable.
  + b. The separability assumption refers to the ability to isolate the effects of different variables or features on an outcome without their interactions complicating the interpretation.This refers to my insight about the linearity assumption; the economist intuition is to separate the effect of the variable of interest from the effect of other features of the model. So one could interperate the regression results counterfactually, i.e., the constant effect of the treatment variable when holding all other features fixed.
  + c. 

# The “Tidyverse”

## 1. Loading (and installing if needed) libraries with pacman
```{r}
pacman::p_load(tidyverse, kableExtra, usethis, git2r)
```

## 2. iris data
```{r}
# Loading the data
data(iris)

# Calculating the mean of the sepal length per species
iris %>% 
  select(starts_with("Sepal"), Species) %>% 
  group_by(Species) %>% 
  summarise(Average_Sepal_Length = mean(Sepal.Length, na.rm = T)) %>% 
  kable() %>% 
  kable_classic(full_width = F)

```


## 3. mtcars data
```{r}
# Loading the data
data(mtcars)

# Setting cyl as a factor
mtcars <- mtcars %>%
  mutate(cyl = as_factor(cyl))

ggplot(mtcars, aes(x = hp, y = mpg, color = cyl)) + 
  geom_point() + 
  geom_smooth(method = "lm")

```

# Git & GitHub

## 1. Introduction to git
I do not need to use commands in this exercise because I have already created my current R project with a Git repository.

## 2. Stagging, Committing and Pushing
I can stage, commit and push in several ways:
a. Using GitHub desktop
b. Using the Git section in R studio
c. Also in R studio, staging and committing using the `r use_git()` and pushing using `r use_github()` (from `r {usethis}` package) in the console.

## 3. Track changes
I can track changes in my repository on GitHub. By clicking on a specific file, I can see green lines for additions and red lines for deletions. I can follow these changes through the commits.